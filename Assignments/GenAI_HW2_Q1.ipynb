{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Perform a full NLP pipeline on a text dataset (Dataset: 20_Newsgroups )**\n",
        "\n"
      ],
      "metadata": {
        "id": "HYKls_SfqDaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install nltk\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings, re, random, os\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "random.seed(42); np.random.seed(42)\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation as SkLDA, PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('stopwords'); nltk.download('vader_lexicon')\n",
        "!pip install gensim scikit-learn matplotlib pandas nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCpx1nPq38DR",
        "outputId": "51483480-ab21-444f-92d8-4bbc0c1d977d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Import the dataset\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "### check all the categories in the dataset\n",
        "cats = fetch_20newsgroups(subset='train').target_names  # or subset='all'\n",
        "print(f\"{len(cats)} categories:\")\n",
        "for i in cats:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHJDZlczuCsX",
        "outputId": "848aa69c-24db-4e63-89e2-b97802de06be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 categories:\n",
            "alt.atheism\n",
            "comp.graphics\n",
            "comp.os.ms-windows.misc\n",
            "comp.sys.ibm.pc.hardware\n",
            "comp.sys.mac.hardware\n",
            "comp.windows.x\n",
            "misc.forsale\n",
            "rec.autos\n",
            "rec.motorcycles\n",
            "rec.sport.baseball\n",
            "rec.sport.hockey\n",
            "sci.crypt\n",
            "sci.electronics\n",
            "sci.med\n",
            "sci.space\n",
            "soc.religion.christian\n",
            "talk.politics.guns\n",
            "talk.politics.mideast\n",
            "talk.politics.misc\n",
            "talk.religion.misc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset (subset of categories)\n",
        "categories = ['rec.sport.baseball', 'sci.space', 'rec.motorcycles', 'sci.crypt']\n",
        "newsgroups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame({'text': newsgroups.data, 'label': newsgroups.target})\n",
        "df['category'] = df['label'].apply(lambda x: newsgroups.target_names[x]) #category name\n",
        "\n",
        "# newsgroups.data → list of raw texts (strings). newsgroups.target → numeric labels (0, 1, 2, 3).\n",
        "# newsgroups.target_names → list of category names in order."
      ],
      "metadata": {
        "id": "FNaGY0SAtORD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocessing the Files**"
      ],
      "metadata": {
        "id": "a89dc_XHufnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Carry out text preprocessing (list all the preprocessing tasks performed).**"
      ],
      "metadata": {
        "id": "L2MFfsTBqMyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet #WordNet is used to support lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "import re #regular expression\n",
        "\n",
        "# Define ALPHA_RE\n",
        "ALPHA_RE = re.compile(r'[^a-zA-Z]')\n",
        "\n",
        "# Map NLTK POS tag to WordNet POS Part of Speech, grammatical category of a word in a sentence — basically, what role the word is playing\n",
        "def _to_wn_pos(tag: str):\n",
        "    t = tag[0].upper() if tag else 'N'\n",
        "    return {'J': wordnet.ADJ, 'N': wordnet.NOUN, 'V': wordnet.VERB, 'R': wordnet.ADV}.get(t, wordnet.NOUN)\n",
        "\n",
        "# returns list of lemmas (tokens)\n",
        "def preprocess_to_tokens(text: str):\n",
        "    text = ALPHA_RE.sub(' ', (text or '')).lower() ## keep only lowercase and english alphabets only areplace with space every other entity\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w for w in tokens if w.isalpha()]\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    return [lemmatizer.lemmatize(w, _to_wn_pos(pos)) for w, pos in pos_tags]\n",
        "\n",
        "df['tokens'] = df['text'].apply(preprocess_to_tokens)\n",
        "#joining list of tokens back into a single cleaned string, so that can be fed to TF_IDF\n",
        "df['clean_text'] = df['tokens'].apply(lambda xs: ' '.join(xs))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "cr1rgfOn3M7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "3cc6b96b-3361-4194-e2b3-d64d0bdd4039"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label         category  \\\n",
              "0  \\n\\n                                          ...      3        sci.space   \n",
              "1  \\n\\nDC-X as is today isn't suitable for this. ...      3        sci.space   \n",
              "2  \\nIf you do make it into New York state, the P...      0  rec.motorcycles   \n",
              "3  \\nThis is a very curious thing to say. STU-III...      2        sci.crypt   \n",
              "4  Hi.\\n\\nI'm not sure what the other guy (can't ...      0  rec.motorcycles   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [jeremy, talk, single, batse, component, whole...   \n",
              "1  [dc, x, today, suitable, however, followon, sd...   \n",
              "2  [make, new, york, state, palisade, interstate,...   \n",
              "3  [curious, thing, say, stu, iii, nsa, design, s...   \n",
              "4  [hi, sure, guy, track, post, name, talk, make,...   \n",
              "\n",
              "                                          clean_text  \n",
              "0  jeremy talk single batse component whole thing...  \n",
              "1  dc x today suitable however followon sdio fund...  \n",
              "2  make new york state palisade interstate parkwa...  \n",
              "3  curious thing say stu iii nsa design secure te...  \n",
              "4  hi sure guy track post name talk make claim co...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1423c379-2a41-40d3-a9c2-7e4703cfb742\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>category</th>\n",
              "      <th>tokens</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n\\n                                          ...</td>\n",
              "      <td>3</td>\n",
              "      <td>sci.space</td>\n",
              "      <td>[jeremy, talk, single, batse, component, whole...</td>\n",
              "      <td>jeremy talk single batse component whole thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n\\nDC-X as is today isn't suitable for this. ...</td>\n",
              "      <td>3</td>\n",
              "      <td>sci.space</td>\n",
              "      <td>[dc, x, today, suitable, however, followon, sd...</td>\n",
              "      <td>dc x today suitable however followon sdio fund...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nIf you do make it into New York state, the P...</td>\n",
              "      <td>0</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "      <td>[make, new, york, state, palisade, interstate,...</td>\n",
              "      <td>make new york state palisade interstate parkwa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThis is a very curious thing to say. STU-III...</td>\n",
              "      <td>2</td>\n",
              "      <td>sci.crypt</td>\n",
              "      <td>[curious, thing, say, stu, iii, nsa, design, s...</td>\n",
              "      <td>curious thing say stu iii nsa design secure te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.\\n\\nI'm not sure what the other guy (can't ...</td>\n",
              "      <td>0</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "      <td>[hi, sure, guy, track, post, name, talk, make,...</td>\n",
              "      <td>hi sure guy track post name talk make claim co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1423c379-2a41-40d3-a9c2-7e4703cfb742')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1423c379-2a41-40d3-a9c2-7e4703cfb742 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1423c379-2a41-40d3-a9c2-7e4703cfb742');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-32336300-f344-4bd6-87ee-4bd454fc54e6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32336300-f344-4bd6-87ee-4bd454fc54e6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-32336300-f344-4bd6-87ee-4bd454fc54e6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3968,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3849,\n        \"samples\": [\n          \"To follow-up, I had a bad experience w/ a Krypto Lock too...\\n\\nLast year I bought a Krypto Cable II (3/8\\\"x3-4' long, something like that)\\nthat by all standards seemed like a decent piece.  Until I used it anyway...\\nBefore I ever used it for security purposes, I used it for entertainment\\n(minds out of the gutter, please), which is to say that I sat fiddling w/\\nit while watching TV (the night I got it).  After three minutes of mindless\\nfiddling (of course it was mindless, remember I was watching TV) the entire\\ntumbler mechanism came out on the key!  Not unlike that old Georgie-porgie\\nnursery rhyme.  This left a very empty cylinder and a very non-secure \\n(read \\\"swingin' in the breeze\\\") cable lock.\\nKinda makes me wonder about any flat key-style lock.  One yank w/ a \\nslide-hammer and Viola-- I'm making an insurance claim.\\n\\nAnyone else have a similar experience (w/ the Kryptos, not bike theft)?\",\n          \"\\n\\nCan you tell us more?\",\n          \"yeah,\\n\\nThey just tore down the Kmart near my house (putting in a new suptermarket).  I\\nheard that there is a beer drinking ghost who still haunts the place!  8-{)\\n\\nTom\\n\\nI liked this one I read a while ago...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"rec.motorcycles\",\n          \"rec.sport.baseball\",\n          \"sci.space\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3831,\n        \"samples\": [\n          \"point really think write pro sdcn anti mediot poster bless certain talent sarcasm bite remark somebody like instance lurid overstatement obviously intend humiliate original poster scale lift eye look like robert really serious oh well compare performance phillies edition outstanding run producer every position except s yet finish frustrate sub level folk ever amount anything neither squad imho parallel previous year team year edition style brave oriole greg mockingbird franklin interracial mixing encompass lot lot f ccit arizona edu mingle g race robohen\",\n          \"document anonymous ftp directory nist look like shoe drop jim gillogly trewesday astron r note file also available via anonymous file transfer csrc ncsl nist gov directory pub nistnews via nist computer security bb white house office press secretary immediate release april statement press secretary president today announce new initiative bring federal government together industry voluntary program improve security privacy telephone communication meeting legitimate need law enforcement initiative involve creation new product accelerate development use advance secure telecommunication network wireless communication link long little dialogue private sector law enforcement community resolve tension economic vitality real challenge protect american rather use technology accommodate sometimes compete interest economic growth privacy law enforcement previous policy pit government industry right privacy law enforcement sophisticated encryption technology use year protect electronic fund transfer use protect electronic mail computer file encryption technology help american protect business secret unauthorized release personal information also use terrorist drug dealer criminal state art microcircuit call clipper chip developed government engineer chip represent new approach encryption technology use new relatively inexpensive encryption device attach ordinary telephone scramble telephone communication use encryption algorithm powerful many commercial use today new technology help company protect proprietary information protect privacy personal phone conversation prevent unauthorized release data transmit electronically time technology preserve ability federal state local law enforcement agency intercept lawfully phone conversation criminal key escrow system establish ensure clipper chip use protect privacy law abide american device contain chip two unique key number need authorized government agency decode message encode device device manufacture two key deposit separately two key escrow data base establish attorney general access key limited government official legal authorization conduct wiretap clipper chip technology provide law enforcement new authority access content private conversation american demonstrate effectiveness new technology attorney general soon purchase several thousand new device addition respect expert outside government offer access confidential detail algorithm assess capability publicly report finding chip important step address problem encryption dual edge sword encryption help protect privacy individual industry also shield criminal terrorist need clipper chip approach provide law abiding citizen access encryption need prevent criminal use hide illegal activity order assess technology trend explore new approach like key escrow system president direct government agency develop comprehensive policy encryption accommodate privacy citizen include need employ voice data encryption business purpose ability authorize official access telephone call data proper court legal order necessary protect citizen effective timely use modern technology build national information infrastructure need promote economic growth competitiveness american industry global marketplace need u company manufacture export high technology product president direct early frequent consultation affect industry congress group advocate privacy right individual policy option develop administration commit work private sector spur development national information infrastructure use new telecommunication computer technology give american unprecedented access information infrastructure high speed network information superhighways transmit video image hdtv program huge data file easily today telephone system transmit voice since encryption technology play increasingly important role infrastructure federal government must act quickly develop consistent comprehensive policy regard use administration commit policy protect american right privacy also protect break law information provide accompany fact sheet provision president directive acquire new encryption technology also available additional detail call mat heyman national institute standard technology question answer clinton administration telecommunication initiative q approach expand authority government agency listen phone conversation clipper chip technology provide law enforcement new authority access content private conversation american q suppose law enforcement agency conduct wiretap drug smuggle ring intercept conversation encrypt use device would decipher message would obtain legal authorization normally court order wiretap first place would present documentation authorization two entity responsible safeguard key obtain key device use drug smuggler key split two part store separately order ensure security key escrow system q run key escrow data bank two key escrow data bank run two independent entity point department justice administration yet determine agency oversee key escrow data bank q strong security device sure strong security system secure many voice encryption system readily available today algorithm remain classified protect security key escrow system willing invite independent panel cryptography expert evaluate algorithm assure potential user unrecognized vulnerability q whose decision propose product national security council justice department commerce department key agency involve decision approach endorse president vice president appropriate cabinet official q consult congress industry go discussion congress industry encryption issue expect discussion intensify carry review encryption policy brief member congress industry leader decision relate initiative q government provide hardware manufacturer government design develop key access encryption microcircuit provide microcircuit product manufacturer product manufacturer acquire microcircuit chip manufacturer produce q provide clipper chip mykotronx program facility torrance california sell chip encryption device manufacturer program function could license vendor future q buy one encryption device expect several manufacturer consider incorporate clipper chip device q administration unable find technological solution like one propose would administration willing use legal remedy restrict access powerful encryption device fundamental policy question consider broad policy review key escrow mechanism provide american encryption product secure convenient less expensive others readily available today one piece must comprehensive approach encryption technology administration develop administration say since encryption threaten public safety effective law enforcement prohibit outright country effectively do u say every american matter right entitle unbreakable commercial encryption product false tension create assessment issue either proposition rather concern fact harmoniously balance reason balanced approach propose clipper chip similar encryption technique q decision indicate clinton administration policy toward encryption differ bush administration indicate understand importance encryption technology telecommunication compute committed work industry public interest group find innovative way protect american privacy help business compete ensure law enforcement agency tool need fight crime terrorism q device exportable device use government hardware voice encryption device subject export control requirement case case review export required ensure appropriate use device true encryption device one attraction technology protection give u company operate home abroad mind expect export license grant case case basis u company seek use device secure communication abroad plan review possibility permit wide exportability product\",\n          \"come periodically get take example mark mcgwire walk time potential great example talk know let look happen mcgwire walk time make time hit single time hit double time hit homer pitching mcgwire would trade walk homer double single out would give base get time guy like alex cole career obp even though never bat average hit ab hit single home run yep right never hit homer ab end afraid throw strike mike jones aix high end development mjones donald aix kingston ibm com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract top keywords using TF-IDF scores**\n",
        "1. Top keywords per category\n",
        "2. Top 10 keywords in the whole corpus"
      ],
      "metadata": {
        "id": "6cVfU3k6qZ6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "## Fit and transform the clean_text Data\n",
        "X_tfidf = vectorizer.fit_transform(df['clean_text'])\n",
        "##Feature names\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(\"Shape of TF-IDF: \", X_tfidf.shape)\n",
        "### Top keywords per category\n",
        "for cat in sorted(df['category'].unique()):\n",
        "    mask = (df['category'] == cat).values\n",
        "    mean_cat = X_tfidf[mask].mean(axis=0).A1\n",
        "    idx = np.argsort(mean_cat)[::-1][:15]\n",
        "    print(f\"\\nTop terms for [{cat}]:\")\n",
        "    for t, s in zip(feature_names[idx], mean_cat[idx]):\n",
        "        print(f\"{t:>22s}  {s:.4f}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "##Top 10 keywords for the whole corpus (not per category)\n",
        "top_n = 10\n",
        "mean_scores = X_tfidf.mean(axis=0).A1  #average across docs\n",
        "top_idx = np.argsort(mean_scores)[::-1][:top_n]\n",
        "top_overall = pd.DataFrame({\n",
        "    \"term\": feature_names[top_idx],\n",
        "    \"mean_tfidf\": mean_scores[top_idx]\n",
        "})\n",
        "print(\"Top 10 keywords in the whole corpus\", top_overall.to_string(index=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unxS7UhlvzNe",
        "outputId": "8879ffc5-54b4-43f1-d8fa-0789e3b63c24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of TF-IDF:  (3968, 5000)\n",
            "\n",
            "Top terms for [rec.motorcycles]:\n",
            "                  bike  0.0584\n",
            "                  ride  0.0225\n",
            "            motorcycle  0.0220\n",
            "                   dod  0.0219\n",
            "                  like  0.0206\n",
            "                   rid  0.0170\n",
            "                   dog  0.0170\n",
            "                 drive  0.0168\n",
            "                  make  0.0165\n",
            "                 think  0.0164\n",
            "                  know  0.0160\n",
            "                   say  0.0141\n",
            "                helmet  0.0140\n",
            "                  look  0.0140\n",
            "                   buy  0.0138\n",
            "\n",
            "\n",
            "\n",
            "Top terms for [rec.sport.baseball]:\n",
            "                  game  0.0515\n",
            "                  year  0.0348\n",
            "                  team  0.0335\n",
            "                   hit  0.0271\n",
            "                player  0.0268\n",
            "              baseball  0.0260\n",
            "                 pitch  0.0250\n",
            "                 think  0.0237\n",
            "                   run  0.0228\n",
            "               pitcher  0.0209\n",
            "                  play  0.0205\n",
            "                   win  0.0196\n",
            "                  good  0.0183\n",
            "                   say  0.0181\n",
            "                  time  0.0176\n",
            "\n",
            "\n",
            "\n",
            "Top terms for [sci.crypt]:\n",
            "                   key  0.0638\n",
            "                  chip  0.0420\n",
            "                   use  0.0378\n",
            "            government  0.0345\n",
            "               clipper  0.0337\n",
            "            encryption  0.0333\n",
            "                 phone  0.0270\n",
            "                people  0.0223\n",
            "                   nsa  0.0223\n",
            "                  know  0.0216\n",
            "             algorithm  0.0201\n",
            "                  make  0.0198\n",
            "                   bit  0.0190\n",
            "                   law  0.0189\n",
            "              security  0.0186\n",
            "\n",
            "\n",
            "\n",
            "Top terms for [sci.space]:\n",
            "                 space  0.0491\n",
            "                launch  0.0219\n",
            "                 orbit  0.0211\n",
            "                  nasa  0.0208\n",
            "                  like  0.0191\n",
            "               shuttle  0.0185\n",
            "                 think  0.0177\n",
            "                   use  0.0172\n",
            "                  moon  0.0169\n",
            "                 earth  0.0166\n",
            "                  know  0.0166\n",
            "               mission  0.0157\n",
            "             satellite  0.0151\n",
            "                  time  0.0143\n",
            "                  cost  0.0139\n",
            "\n",
            "\n",
            "Top 10 keywords in the whole corpus     term  mean_tfidf\n",
            "0  think    0.018735\n",
            "1    use    0.018330\n",
            "2   know    0.017734\n",
            "3   like    0.017721\n",
            "4    key    0.016630\n",
            "5   year    0.016105\n",
            "6   make    0.015997\n",
            "7    say    0.015143\n",
            "8   bike    0.014658\n",
            "9   time    0.014313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform named entity recognition (NER, Using spacy) to identify entities**"
      ],
      "metadata": {
        "id": "LGSAmQmdKBqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing spacy and and a small english model"
      ],
      "metadata": {
        "id": "YmbWyfIc8D8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrade packaging basics FIRST (you removed setuptools)\n",
        "!pip -q install -U pip setuptools wheel\n",
        "\n",
        "# Install spaCy + a compatible typer to avoid gradio warnings\n",
        "!pip -q install -U \"spacy==3.7.2\" \"typer>=0.12,<1.0\"\n",
        "\n",
        "# Download the small English model\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj0h-zamet7U",
        "outputId": "9ca04964-f76c-4cfe-ed9a-210bca9a32c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Cannot install spacy==3.7.2 and typer<1.0 and >=0.12 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "smoke Test to check if its working fine or not?"
      ],
      "metadata": {
        "id": "jokKCzqI8IJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Smoke test\n",
        "import spacy\n",
        "nlp_ner = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp_ner(\"NASA launched the Hubble Space Telescope in April 1990.\")\n",
        "[(ent.text, ent.label_) for ent in doc.ents]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW_nYsvVe2lN",
        "outputId": "7ec2a133-cb41-4c23-f3b4-21f18bc64f37"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NASA', 'ORG'),\n",
              " ('the Hubble Space Telescope', 'ORG'),\n",
              " ('April 1990', 'DATE')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spaCy’s Named Entity Recognition (NER) to pull out entities (like people, places, dates, organizations) from text. It then previews the results for the first four documents in your dataset, showing each document’s category and its detected"
      ],
      "metadata": {
        "id": "fIPnCrpg9Q58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_entities(text: str):\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return []\n",
        "    doc = nlp_ner(text)\n",
        "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
        "# Preview on a 4 docs\n",
        "for i in range(4):\n",
        "    ents = extract_entities(df.loc[i, 'text'])\n",
        "    print(f\"\\nDoc {i} | Category: {df.loc[i,'category']}\")\n",
        "    print(ents[:12])"
      ],
      "metadata": {
        "id": "fXBmU5KfiLb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4299843b-388b-45b2-cd60-1c5e5eb410bd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Doc 0 | Category: sci.space\n",
            "[('BATSE', 'ORG'), ('BATSE', 'ORG'), ('two', 'CARDINAL'), ('three', 'CARDINAL')]\n",
            "\n",
            "Doc 1 | Category: sci.space\n",
            "[('today', 'DATE'), ('I.', 'ORG'), ('bush', 'PERSON'), ('Allen\\n', 'PERSON')]\n",
            "\n",
            "Doc 2 | Category: rec.motorcycles\n",
            "[('New York', 'GPE'), ('the Palisades Interstate Parkway', 'ORG'), ('Seven', 'CARDINAL'), ('Lakes Drive', 'ORG')]\n",
            "\n",
            "Doc 3 | Category: sci.crypt\n",
            "[('STU', 'ORG'), ('FBI', 'ORG'), ('several hundred\\nthousand', 'CARDINAL'), ('US', 'GPE'), ('DoJ', 'ORG'), ('STU', 'ORG'), ('STU', 'ORG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['entities'] = df['text'].apply(extract_entities)\n",
        "# 2) Build table\n",
        "rows = []\n",
        "for i, (cat, ents) in enumerate(zip(df.get('category', pd.Series([None]*len(df))), df['entities'])):\n",
        "    for txt, lab in ents:\n",
        "        rows.append({\"doc_id\": i, \"category\": cat, \"entity\": txt, \"label\": lab})\n",
        "ents_df = pd.DataFrame(rows)\n",
        "print(\"Entities table:\", ents_df.shape)"
      ],
      "metadata": {
        "id": "Mn7eCdTsvSJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5227a796-1b3a-494c-d528-110a3ffcce10"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities table: (51813, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ents_df['label'].value_counts().to_frame('count')\n",
        "top_per_label = (\n",
        "    ents_df.groupby(['label','entity'])\n",
        "           .size().reset_index(name='count')\n",
        "           .sort_values(['label','count'], ascending=[True, False])\n",
        ")\n",
        "\n",
        "for lbl in top_per_label['label'].unique():\n",
        "    print(f\"\\nTop entities for label = {lbl}\")\n",
        "    print(top_per_label[top_per_label['label'] == lbl].head(10))\n"
      ],
      "metadata": {
        "id": "8amKsG5avZGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd0023b-185d-4005-d3aa-dc1e2b4c94e6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top entities for label = CARDINAL\n",
            "         label entity  count\n",
            "2721  CARDINAL    one    679\n",
            "608   CARDINAL      1    657\n",
            "2805  CARDINAL    two    633\n",
            "1188  CARDINAL      2    548\n",
            "1476  CARDINAL      3    439\n",
            "67    CARDINAL      0    356\n",
            "1669  CARDINAL      4    301\n",
            "1843  CARDINAL      5    253\n",
            "2796  CARDINAL  three    183\n",
            "2437  CARDINAL    One    168\n",
            "\n",
            "Top entities for label = DATE\n",
            "     label     entity  count\n",
            "5602  DATE      today    154\n",
            "5057  DATE  last year    116\n",
            "3663  DATE       1993    103\n",
            "5579  DATE  this year     98\n",
            "3662  DATE       1992     96\n",
            "3643  DATE       1988     71\n",
            "3651  DATE       1990     69\n",
            "3655  DATE       1991     53\n",
            "5667  DATE  yesterday     46\n",
            "5662  DATE      years     43\n",
            "\n",
            "Top entities for label = EVENT\n",
            "      label                 entity  count\n",
            "5708  EVENT                   WWII     13\n",
            "5701  EVENT                 Series     10\n",
            "5741  EVENT       the World Series     10\n",
            "5715  EVENT           World Series      6\n",
            "5677  EVENT              Civil War      3\n",
            "5695  EVENT   Operation Sun Devil'      3\n",
            "5712  EVENT              Watergate      3\n",
            "5718  EVENT           World War II      3\n",
            "5722  EVENT  the \"Big Brother Chip      3\n",
            "5674  EVENT  Asteroid Belt Passage      2\n",
            "\n",
            "Top entities for label = FAC\n",
            "     label                entity  count\n",
            "5890   FAC                 Venus     27\n",
            "5835   FAC                   Mir     19\n",
            "5811   FAC                Hubble     11\n",
            "5880   FAC                 Stick      9\n",
            "5922   FAC      the Hall of Fame      9\n",
            "5867   FAC                  SSTO      8\n",
            "5820   FAC  Kennedy Space Center      5\n",
            "5829   FAC  Massachusetts Avenue      5\n",
            "5897   FAC           White Sands      5\n",
            "5902   FAC        Yankee Stadium      5\n",
            "\n",
            "Top entities for label = GPE\n",
            "     label      entity  count\n",
            "6856   GPE          US    202\n",
            "6851   GPE        U.S.    172\n",
            "6545   GPE    New York     68\n",
            "6905   GPE  Washington     64\n",
            "6101   GPE      Canada     59\n",
            "6095   GPE  California     58\n",
            "6855   GPE          UK     50\n",
            "6857   GPE         USA     46\n",
            "6062   GPE      Boston     44\n",
            "6347   GPE       Japan     43\n",
            "\n",
            "Top entities for label = LANGUAGE\n",
            "         label       entity  count\n",
            "7053  LANGUAGE      English     44\n",
            "7057  LANGUAGE      Spanish     16\n",
            "7060  LANGUAGE      english      5\n",
            "7054  LANGUAGE       Hebrew      2\n",
            "7055  LANGUAGE        Latin      2\n",
            "7059  LANGUAGE    Taiwanese      2\n",
            "7056  LANGUAGE  Spaceflight      1\n",
            "7058  LANGUAGE      Tagalog      1\n",
            "\n",
            "Top entities for label = LAW\n",
            "     label                 entity  count\n",
            "7084   LAW           Constitution     18\n",
            "7153   LAW      the \"Clipper Chip     17\n",
            "7184   LAW   the Second Amendment     17\n",
            "7164   LAW       the Clipper Chip     11\n",
            "7162   LAW     the Bill of Rights      9\n",
            "7135   LAW              VENERA 15      5\n",
            "7070   LAW         Bill of Rights      3\n",
            "7074   LAW  CB650 \\t\\t\\t\\t\\t\\tDoD      3\n",
            "7128   LAW               Title 18      3\n",
            "7061   LAW                  900SS      2\n",
            "\n",
            "Top entities for label = LOC\n",
            "     label    entity  count\n",
            "7225   LOC     Earth    261\n",
            "7254   LOC      Mars     87\n",
            "7248   LOC   Jupiter     76\n",
            "7301   LOC       Sun     19\n",
            "7285   LOC   Rockies     17\n",
            "7305   LOC     Venus     17\n",
            "7238   LOC    Europe     16\n",
            "7223   LOC     Delta     12\n",
            "7203   LOC  Atlantic     10\n",
            "7224   LOC      EAST      9\n",
            "\n",
            "Top entities for label = MONEY\n",
            "      label      entity  count\n",
            "7486  MONEY           1     23\n",
            "7561  MONEY          20     16\n",
            "7751  MONEY        Date     15\n",
            "7503  MONEY         100     14\n",
            "7552  MONEY           2     12\n",
            "7621  MONEY          35     11\n",
            "7529  MONEY          15     10\n",
            "7382  MONEY  $1 billion      9\n",
            "7599  MONEY           3      9\n",
            "7667  MONEY          50      9\n",
            "\n",
            "Top entities for label = NORP\n",
            "     label     entity  count\n",
            "7887  NORP   American     80\n",
            "7888  NORP  Americans     63\n",
            "8094  NORP    Russian     56\n",
            "8120  NORP     Soviet     50\n",
            "8008  NORP   Japanese     45\n",
            "8011  NORP     Jewish     31\n",
            "8109  NORP    Shuttle     28\n",
            "7909  NORP    British     23\n",
            "7966  NORP       Feds     23\n",
            "7958  NORP   European     21\n",
            "\n",
            "Top entities for label = ORDINAL\n",
            "        label  entity  count\n",
            "8278  ORDINAL   first    727\n",
            "8281  ORDINAL  second    234\n",
            "8286  ORDINAL   third    127\n",
            "8264  ORDINAL   First     61\n",
            "8277  ORDINAL   fifth     42\n",
            "8269  ORDINAL  Second     35\n",
            "8279  ORDINAL  fourth     32\n",
            "8244  ORDINAL     3rd     26\n",
            "8247  ORDINAL     4th     22\n",
            "8280  ORDINAL   ninth     21\n",
            "\n",
            "Top entities for label = ORG\n",
            "      label    entity  count\n",
            "10904   ORG      NASA    327\n",
            "11002   ORG       NSA    246\n",
            "9703    ORG       FTP    131\n",
            "8842    ORG    Braves    102\n",
            "11307   ORG       PGP    102\n",
            "11606   ORG       RSA     99\n",
            "9670    ORG       FBI     98\n",
            "8698    ORG       BMW     86\n",
            "9667    ORG       FAQ     83\n",
            "9233    ORG  Congress     68\n",
            "\n",
            "Top entities for label = PERCENT\n",
            "         label entity  count\n",
            "13576  PERCENT   100%     15\n",
            "13574  PERCENT    10%     10\n",
            "13637  PERCENT    50%     10\n",
            "13571  PERCENT     1%      8\n",
            "13655  PERCENT    80%      8\n",
            "13634  PERCENT     5%      7\n",
            "13666  PERCENT    90%      7\n",
            "13595  PERCENT     2%      4\n",
            "13601  PERCENT    20%      4\n",
            "13611  PERCENT    25%      4\n",
            "\n",
            "Top entities for label = PERSON\n",
            "        label       entity  count\n",
            "16716  PERSON         Moon    111\n",
            "16725  PERSON       Morris     83\n",
            "14500  PERSON      Clinton     82\n",
            "14736  PERSON        David     53\n",
            "17989  PERSON       Usenet     45\n",
            "14868  PERSON      Dodgers     29\n",
            "15507  PERSON   Hirschbeck     29\n",
            "15716  PERSON         Jays     29\n",
            "16881  PERSON         Oort     28\n",
            "16506  PERSON  Mary Shafer     26\n",
            "\n",
            "Top entities for label = PRODUCT\n",
            "         label    entity  count\n",
            "18634  PRODUCT   Clipper     58\n",
            "18810  PRODUCT    Saturn     50\n",
            "18664  PRODUCT         F     34\n",
            "18695  PRODUCT   Galileo     31\n",
            "18632  PRODUCT   Clemens     30\n",
            "18869  PRODUCT   Voyager     22\n",
            "18715  PRODUCT        K2     13\n",
            "18736  PRODUCT  Magellan     13\n",
            "18799  PRODUCT        S1     13\n",
            "18603  PRODUCT        CA     12\n",
            "\n",
            "Top entities for label = QUANTITY\n",
            "          label            entity  count\n",
            "19471  QUANTITY            80-bit     28\n",
            "19308  QUANTITY            40-bit      7\n",
            "19008  QUANTITY      10.00 pounds      6\n",
            "19258  QUANTITY            34-bit      6\n",
            "19357  QUANTITY            50 mph      6\n",
            "19530  QUANTITY            a mile      5\n",
            "18985  QUANTITY             1-bit      4\n",
            "19006  QUANTITY          10-meter      4\n",
            "19256  QUANTITY  34 meter antenna      4\n",
            "19387  QUANTITY            56-bit      4\n",
            "\n",
            "Top entities for label = TIME\n",
            "      label         entity  count\n",
            "20080  TIME        tonight     27\n",
            "20038  TIME          night     22\n",
            "20021  TIME     last night     21\n",
            "20075  TIME   this morning     14\n",
            "19820  TIME       24 hours     12\n",
            "20036  TIME        morning     12\n",
            "20004  TIME        evening     10\n",
            "19879  TIME        5:35 pm      9\n",
            "19954  TIME  a few minutes      8\n",
            "19962  TIME       a minute      8\n",
            "\n",
            "Top entities for label = WORK_OF_ART\n",
            "             label                                entity  count\n",
            "20218  WORK_OF_ART                          Clipper Chip     22\n",
            "20161  WORK_OF_ART                     Astronomy & Space      7\n",
            "20476  WORK_OF_ART               Streak    Home   Road\\n      7\n",
            "20444  WORK_OF_ART                               Slaught      5\n",
            "20479  WORK_OF_ART  Streak    Home   Road\\nTexas Rangers      5\n",
            "20498  WORK_OF_ART                     The \"Clipper Chip      5\n",
            "20625  WORK_OF_ART               the \"Clipper\\n     Chip      5\n",
            "20216  WORK_OF_ART                               Clipper      4\n",
            "20315  WORK_OF_ART                               Hellman      4\n",
            "20361  WORK_OF_ART                       Memory Readouts      4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'category' in df.columns:\n",
        "    top_per_cat = (\n",
        "        ents_df.groupby(['category','entity'])\n",
        "               .size().reset_index(name='count')\n",
        "               .sort_values(['category','count'], ascending=[True, False])\n",
        "    )\n",
        "    for cat in sorted(df['category'].dropna().unique()):\n",
        "        print(f\"\\nTop entities in category = {cat}\")\n",
        "        print(top_per_cat[top_per_cat['category'] == cat].head(10))\n"
      ],
      "metadata": {
        "id": "-nXxa6fbvcru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965d1b48-7a3f-4ad4-f727-a159e48a6d70"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top entities in category = rec.motorcycles\n",
            "             category  entity  count\n",
            "2562  rec.motorcycles   first    117\n",
            "2664  rec.motorcycles     one    116\n",
            "2883  rec.motorcycles     two     95\n",
            "721   rec.motorcycles     BMW     86\n",
            "226   rec.motorcycles       2     60\n",
            "1314  rec.motorcycles   Honda     51\n",
            "59    rec.motorcycles       1     44\n",
            "1775  rec.motorcycles     One     31\n",
            "2710  rec.motorcycles  second     31\n",
            "309   rec.motorcycles       3     28\n",
            "\n",
            "Top entities in category = rec.sport.baseball\n",
            "                category     entity  count\n",
            "3574  rec.sport.baseball          1    371\n",
            "3045  rec.sport.baseball          0    331\n",
            "3936  rec.sport.baseball          2    242\n",
            "4110  rec.sport.baseball          3    240\n",
            "8027  rec.sport.baseball      first    209\n",
            "4251  rec.sport.baseball          4    182\n",
            "4351  rec.sport.baseball          5    168\n",
            "8595  rec.sport.baseball        two    144\n",
            "8179  rec.sport.baseball        one    116\n",
            "8105  rec.sport.baseball  last year    106\n",
            "\n",
            "Top entities in category = sci.crypt\n",
            "        category entity  count\n",
            "13568  sci.crypt    one    273\n",
            "11946  sci.crypt    NSA    246\n",
            "13979  sci.crypt    two    236\n",
            "13419  sci.crypt  first    173\n",
            "9482   sci.crypt      2    143\n",
            "8936   sci.crypt      1    129\n",
            "12371  sci.crypt    RSA    117\n",
            "12937  sci.crypt   U.S.    112\n",
            "12148  sci.crypt    PGP    102\n",
            "10990  sci.crypt    FBI     98\n",
            "\n",
            "Top entities in category = sci.space\n",
            "        category entity  count\n",
            "18783  sci.space   NASA    323\n",
            "17236  sci.space  Earth    258\n",
            "21122  sci.space  first    228\n",
            "21335  sci.space    one    174\n",
            "21993  sci.space    two    158\n",
            "14205  sci.space      1    136\n",
            "14851  sci.space      2    116\n",
            "18735  sci.space   Moon    112\n",
            "20540  sci.space  Venus    107\n",
            "15189  sci.space      3     99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Represent text with pretrained embeddings (e.g., Word2Vec, GloVe).**"
      ],
      "metadata": {
        "id": "z6VArnnbKHya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "glove = api.load(\"glove-wiki-gigaword-100\") # Glove, 128 MB\n",
        "google = api.load(\"word2vec-google-news-300\") # Word2Vec, 1.16 GB huge data\n",
        "\n",
        "print(\"GloVe dims/vocab:\", glove.vector_size, len(glove.key_to_index))\n",
        "print(\"GoogleNews dims/vocab:\", google.vector_size, len(google.key_to_index))\n"
      ],
      "metadata": {
        "id": "zCmwWKr9EsPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "info = api.info()\n",
        "pprint.pp(info['models']['glove-wiki-gigaword-100'])\n",
        "pprint.pp(info['models']['word2vec-google-news-300'])\n",
        "print(glove['the'].shape)    # (100,)\n",
        "print(google['the'].shape)   # (300,)\n"
      ],
      "metadata": {
        "id": "cVJY1u1LEv9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wv = glove        # wv = google\n",
        "\n",
        "print(\"Using:\", \"GloVe\" if wv is glove else \"GoogleNews\",\n",
        "      \"| dims:\", wv.vector_size, \"| vocab:\", len(wv.key_to_index))"
      ],
      "metadata": {
        "id": "d5K5OWmXX739"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim = wv.vector_size\n",
        "E = np.zeros((len(feature_names), emb_dim), dtype=np.float32)\n",
        "oov = 0\n",
        "for i, term in enumerate(feature_names):\n",
        "    if term in wv.key_to_index:\n",
        "        E[i] = wv[term]\n",
        "    else:\n",
        "        oov += 1\n",
        "print(f\"OOV terms: {oov}/{len(feature_names)}\")\n",
        "\n",
        "# 4. Document embeddings: TF-IDF @ Embedding matrix\n",
        "doc_emb = X_tfidf @ E\n",
        "doc_emb = doc_emb / (np.linalg.norm(doc_emb, axis=1, keepdims=True) + 1e-12)  # normalize\n",
        "print(\"Document embeddings shape:\", doc_emb.shape)  # (n_docs, emb_dim)"
      ],
      "metadata": {
        "id": "2tkpZNY1aFNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display the TF-IDF matrix (or a sample) and visualize the word embeddings in 2D space (eg: t-SNE)**"
      ],
      "metadata": {
        "id": "gZhc79kpKJbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "rows = min(10, X_tfidf.shape[0])\n",
        "cols = min(15, len(feature_names))\n",
        "tfidf_sample = pd.DataFrame(\n",
        "    X_tfidf[:rows, :cols].toarray(),\n",
        "    columns=feature_names[:cols]\n",
        ").round(3)\n",
        "\n",
        "print(\"TF-IDF shape:\", X_tfidf.shape)\n",
        "tfidf_sample  # Colab will render this as a table\n"
      ],
      "metadata": {
        "id": "DBAwoZ9Ac_sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# choose up to 300 TF-IDF vocab terms that exist in the pretrained model\n",
        "viz_words = [w for w in feature_names if w in wv.key_to_index][:300]\n",
        "W = np.vstack([wv[w] for w in viz_words])  # (n_words, emb_dim)\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=30, random_state=42, init=\"pca\", learning_rate=\"auto\")\n",
        "coords = tsne.fit_transform(W)\n",
        "\n",
        "tsne_df = pd.DataFrame(coords, columns=[\"x\",\"y\"]); tsne_df[\"word\"] = viz_words\n",
        "print(tsne_df.head())\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(tsne_df.x, tsne_df.y, s=10)\n",
        "# annotate a light subset to avoid clutter\n",
        "for i in range(0, len(tsne_df), max(1, len(tsne_df)//50)):\n",
        "    r = tsne_df.iloc[i]; plt.annotate(r.word, (r.x, r.y), fontsize=8, alpha=0.8)\n",
        "plt.title(\"t-SNE of Pretrained Word Embeddings (GloVe)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ccyTllIVdFtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sub = min(800, doc_emb.shape[0])\n",
        "coords = TSNE(n_components=2, perplexity=30, random_state=42, init=\"pca\", learning_rate=\"auto\") \\\n",
        "         .fit_transform(doc_emb[:sub])\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(coords[:,0], coords[:,1], s=6)\n",
        "plt.title(\"t-SNE of Document Embeddings (TF-IDF-weighted GloVe)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "waHIJhjjKV7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform sentiment analysis (positive/negative/neutral), topic modeling using LDA, extractive summarization of long reviews**"
      ],
      "metadata": {
        "id": "jqiQndgYKP6e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b55bf2da"
      },
      "source": [
        "## Perform topic modeling using lda\n",
        "\n",
        "### Subtask:\n",
        "Apply Latent Dirichlet Allocation (LDA) to the TF-IDF matrix to identify the main topics within the documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8d33a1b"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply Latent Dirichlet Allocation (LDA) to the TF-IDF matrix to identify the main topics within the documents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "applied the get_sentiment function to your DataFrame's 'text' column, categorized each text's sentiment, added the results to a 'sentiment' column, and printed the sentiment counts."
      ],
      "metadata": {
        "id": "dYfGxx3tCtZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def get_sentiment(text):\n",
        "    c = sia.polarity_scores(str(text))['compound']\n",
        "    return \"positive\" if c >= 0.05 else (\"negative\" if c <= -0.05 else \"neutral\")\n",
        "\n",
        "df['sentiment'] = df['text'].apply(get_sentiment)\n",
        "print(\"Sentiment distribution:\\n\", df['sentiment'].value_counts(), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBuf8xPSwupG",
        "outputId": "d49643dc-b848-42fa-d071-97ee762d4a94"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment distribution:\n",
            " sentiment\n",
            "positive    2412\n",
            "negative    1032\n",
            "neutral      524\n",
            "Name: count, dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Topic modeling using LDA"
      ],
      "metadata": {
        "id": "uW3uIN0Kb-ns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for 4 categories"
      ],
      "metadata": {
        "id": "yyH1k-vacC5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import numpy as np\n",
        "\n",
        "cv = CountVectorizer(max_features=6000, stop_words='english', min_df=5, ngram_range=(1,1))\n",
        "X_counts = cv.fit_transform(df['clean_text'])\n",
        "terms = cv.get_feature_names_out()\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=4, learning_method='batch', random_state=42)\n",
        "lda.fit(X_counts)\n",
        "\n",
        "# Top words per topic\n",
        "topn = 12\n",
        "for k, comp in enumerate(lda.components_):\n",
        "    idx = np.argsort(comp)[::-1][:topn]\n",
        "    print(f\"Topic {k}: \" + \", \".join(terms[i] for i in idx))\n",
        "\n",
        "# Doc → topic mixture + dominant topic\n",
        "doc_topic = lda.transform(X_counts)                 # (n_docs, 4)\n",
        "df['topic_id'] = doc_topic.argmax(axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeW0TnFrK5OI",
        "outputId": "9be430aa-5741-4349-f11e-16ce33070326"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: year, game, db, think, team, hit, good, run, time, player, like, make\n",
            "Topic 1: use, mail, key, post, message, list, edu, know, like, anonymous, com, public\n",
            "Topic 2: space, launch, nasa, orbit, mission, satellite, use, earth, data, program, shuttle, information\n",
            "Topic 3: key, use, chip, government, make, bike, like, know, people, think, encryption, right\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extractive summarization of long reviews\n"
      ],
      "metadata": {
        "id": "sCcroP_ScHC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install sumy\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "\n",
        "def summarize_lexrank(text, n_sent=3):\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return \"\"\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    summary = LexRankSummarizer()(parser.document, n_sent)\n",
        "    return \" \".join(str(s) for s in summary)\n",
        "\n",
        "# Apply to long docs only (optional filter)\n",
        "df['summary'] = df['text'].apply(lambda t: summarize_lexrank(t, n_sent=3))\n",
        "\n",
        "# Preview\n",
        "df[['sentiment','topic_id','summary']].head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "BG1s-qH6LBYj",
        "outputId": "73f4fb4e-a6da-4767-b244-1b6cad7542db"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  sentiment  topic_id                                            summary\n",
              "0  positive         2  -jeremy Are you talking about a single BATSE c...\n",
              "1  positive         2  DC-X as is today isn't suitable for this. Howe...\n",
              "2  positive         3  If you do make it into New York state, the Pal...\n",
              "3  positive         3  This is a very curious thing to say. STU-IIIs ...\n",
              "4  positive         3  Also, (and this is not applicable to hard-core..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3ad811d-3b4f-4d95-9951-d883585b0a82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>topic_id</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "      <td>-jeremy Are you talking about a single BATSE c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "      <td>DC-X as is today isn't suitable for this. Howe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>3</td>\n",
              "      <td>If you do make it into New York state, the Pal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>3</td>\n",
              "      <td>This is a very curious thing to say. STU-IIIs ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>3</td>\n",
              "      <td>Also, (and this is not applicable to hard-core...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3ad811d-3b4f-4d95-9951-d883585b0a82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3ad811d-3b4f-4d95-9951-d883585b0a82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3ad811d-3b4f-4d95-9951-d883585b0a82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bcfed483-0900-485b-9f1d-6bee3b28aeb8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bcfed483-0900-485b-9f1d-6bee3b28aeb8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bcfed483-0900-485b-9f1d-6bee3b28aeb8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['sentiment','topic_id','summary']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"DC-X as is today isn't suitable for this. However, the followon SDIO funds will. The insiders have been very bush briefing the right people and it is now paying off.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}